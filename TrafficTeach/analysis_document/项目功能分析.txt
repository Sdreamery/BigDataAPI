卡口状态监控：
	正常卡口数，异常卡口数
	正常摄像头数，异常摄像头数
	异常卡口信息：
		monitor_id: camera_id
		00876: 8735,5463

mapToPair、mapPartitionsToPair的区别:
跟数据库打交道时，要用到mapPartition，同foreachPartiton相同，用partiton时，会将数据以一个Iterator的形式传进来，
只需要创建一次数据库连接就可以，不然来一次数据就创建一次连接，太消耗资源。

BUG01：
如果后面的代码要用到注册临时表里的数据，在使用临时表之前，不能关闭SparkContext，不然无法找到，会报空指针。

去重：
1、distinct
2、groupByKey+mapToPair


1、求出卡口流量TopN

生成标准表monitor_flow_action -> dateFrame -> 原始数据RDD1(row) -> mapToPair -> RDD2(monitor_id,row) 
-> groupByKey -> RDD3(monitor_id,[row,row...]) -> mapToPair -> RDD4(monitor_id,cameraInfo|cameraCount|carCount)

生成实际表monitor_camera_info -> dateFrame -> 原始数据RDD_A(row) -> mapToPair -> RDD_B(monitor_id,row) 
-> groupByKey -> RDD_C(monitor_id,[row,row...]) -> mapToPair -> RDD_D(monitor_id,cameraInfo|cameraCount|carCount)

RDD4.rightOuterJoin(RDD_D) -> RDD5(monitor_id,(acInfo,standInfo)) -> mapPartitonToPair -> 
RDD6(carCount,monitor_id) -> sorByKey -> RDD7(carCount,monitor_id) -> tack(N) -> result


2、卡口流量TopN具体车辆

方法一：使用join合并，自动过滤

原始数据RDD1(row) -> mapToPair -> RDD2(monitor_id,row)

原始数据topN -> RDD_A(monitor_id) -> mapToPair -> RDD_B(monitor_id,monitor_id)

RDD2.join(RDD_B) -> RDD3(monitor_id,(monitor_id,row)) -> mapToPair -> RDD4(monitor_id,row) -> foreachPartiton

方法二：使用广播变量 + filter

RDD1(row) -> filter + List<monitor_id>.broadcast() -> resultRDD(row)


3、求出高速卡口TopN，以及卡口下面的topY车速的车辆

原始数据RDD1(row) -> mapToPair -> RDD2(monitor_id,row) -> groupByKey -> RDD3(monitor_id,[row,row...]) 
-> mapToPair -> RDD4(speedKey,monitor_id) -> sorByKey -> RDD5(speedKey,monitor_id) -> tack(N) -> result

原始数据RDD3(monitor_id,[row,row...]) -> filter + result.broadcast() -> RDD6(monitor_id,row) -> foreach
-> result

/* 优化如上，直接使用上次已经groupByKey的RDD3
 * 原始数据RDD2(monitor_id,row) -> filter + result.broadcast() -> RDD6(monitor_id,row) -> groupByKey -> 
 * RDD7(monitor_id,[row,row...]) -> foreach -> result
 */


4、求出经过卡口XXX（0001）的车辆轨迹

原始数据RDD1(row) -> mapToPair -> RDD2(monitor_id,row) -> filter -> RDD3(monitor_id,row) -> map ->
RDD4(carId) -> distinct -> RDD5(carId) -> collect -> List<carId>

原始数据RDD1(row) -> mapToPair -> RDD_A(carId,row) -> filter + List(carId).broadcast -> RDD6(carId,row)
-> groupByKey -> RDD7(carId,[row,row...]) -> foreach -> TreeMap按时间排序


5、随机抽取车辆，求行车轨迹

原始数据RDD1(row) -> mapToPair -> RDD2(date_hour,carId) -> distinct -> RDD3(date_hour,carId) -> countByKey
-> Map<date_hour,count> -> Map<date, Map<hour, List<Integer>>>

RDD3(date_hour,carId) -> groupByKey -> RDD4(date_hour,[carid,carId...]) -> flatMapToPair + 
Map<date, Map<hour, List<Integer>>>.broadcast -> RDD5(carId,carId)  

原始数据RDD1(row) -> mapToPair -> RDD_A(carId,row) -> filter + RDD5 -> RDD6(carId,(carId,row)) -> 
mapPartitonToPair -> RDD7(car,row) -> groupBykey -> RDD8(carId,[row,row...]) -> foreach -> result


6、区域碰撞分析(多个区域进行join)

原始数据RDD1(row) -> mapToPair -> RDD2(carId,row) -> groupByKey -> RDD3(carId,[row,row...]) -> maoToPair -> RDD4(carId,carId)

原始数据RDD_A(row) -> mapToPair -> RDD_B(carId,row) -> groupByKey -> RDD_C(carId,[row,row...]) -> maoToPair -> RDD_D(carId,carId)

RDD4.join.RDD_D -> foreach -> result


7、卡口碰撞分析（与区域碰撞分析类似）
把卡口号放入List，组成多个List，然后查看这些List中相同的车牌号


8、道路转化率

原始数据RDD1(row) -> mapToPair -> RDD2(carId,row) -> groupByKey -> RDD3(carId,[row,row...]) -> flatMapToPair -> RDD4(monitor_id,monitor_id_count) -> reduceByKey
-> RDD5(monitor_id,monitor_id_count) -> collect -> List<Tuple2>


9、每个区域道路流量TopN

原始数据RDD1(row<从DataFrame的sql中得到>) -> mapToPair -> RDD2(areaId,row1<monitorId,carId,roadId,areaId>)

原始数据RDD_A(row<从Mysql的sql中得到>) -> mapToPair -> RDD_B(areaId,row2<areaId,areaName>)

RDD2.join(RDD_B) -> RDD3(areaId,(row1,row2)) -> map -> RDD4(areaId,row3<areaId,areaName,monitorId,carId,roadId>) -> 用sql自定义函数求出各区域每条道路每个卡口下的车流量 -> 转成DataFrame注册临时表 
-> 用sql开窗函数取car_count 前3个 -> result


10、道路实时拥堵分析
通过KafkaUtils.createDirectStream()方法创建 DStream1(null,row) -> map 
-> DStream2(row) -> mapToPair -> DStream3(monitorId,speed) -> mapValues
-> DStream3(monitorId,(speed,1)) -> reduceByKeyAndWindow -> DStream4(monitorId,(speedCount,count)) -> foreachRDD -> foreachPartition -> RDD1(monitorId,<speedCount,count>) 